`Weapon Used` = as.numeric(factor("Blunt Object", levels = levels(as.factor(train_data$`Weapon Used`)))),
`Police Deployed` = 2
)
# Convert the new tuple to matrix format
new_tuple_matrix <- as.matrix(new_tuple)
colnames(new_tuple_matrix) <- colnames(train_matrix)
# Predict using the trained XGBoost model
new_prediction <- predict(xgb_model, new_tuple_matrix)
# Convert probability to class label (0 or 1)
predicted_class <- ifelse(new_prediction > 0.5, "Violent Crime", "Nonviolent Crime")
# Output the result
print(paste("Predicted Crime Domain:", predicted_class))
print(paste("Prediction Probability:", new_prediction))
# Load necessary libraries
library(readr)
library(randomForest)  # Changed from xgboost to randomForest
library(caret)  # For confusion matrix
# Load the data set
crime_data <- read_csv("crime_dataset_india.csv")
# Data Preprocessing
crime_data_model <- subset(crime_data, select = -c(`Report Number`, `Date Reported`,
`Date of Occurrence`, `Time of Occurrence`,
`Date Case Closed`, `Case Closed`))
# Convert Crime Domain to binary (0 and 1)
crime_data_model$`Crime Domain` <- ifelse(crime_data_model$`Crime Domain` == "Violent Crime", 1, 0)
# Convert character columns to factors
crime_data_model$City <- as.factor(crime_data_model$City)
crime_data_model$`Crime Description` <- as.factor(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.factor(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.factor(crime_data_model$`Weapon Used`)
# Convert factors to numeric (preserving levels)
crime_data_model$City <- as.numeric(crime_data_model$City)
crime_data_model$`Crime Description` <- as.numeric(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.numeric(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.numeric(crime_data_model$`Weapon Used`)
crime_data_model$`Police Deployed` <- as.numeric(crime_data_model$`Police Deployed`)
# Data Splitting (reproducible)
set.seed(123)
train_index <- sample(1:nrow(crime_data_model), 0.8 * nrow(crime_data_model))
train_data <- crime_data_model[train_index, ]
test_data <- crime_data_model[-train_index, ]
# Prepare Data for randomForest
train_data$`Crime Domain` <- as.factor(train_data$`Crime Domain`)  # Crucial: Convert target to factor
test_data$`Crime Domain` <- as.factor(test_data$`Crime Domain`)    # Ensure test target is also a factor
# Train randomForest Model
rf_model <- randomForest(`Crime Domain` ~ ., data = train_data, ntree = 500)
# Load necessary libraries
library(readr)
library(randomForest)
library(caret)
# Load the data set
crime_data <- read_csv("crime_dataset_india.csv")
# Data Preprocessing
crime_data_model <- subset(crime_data, select = -c(`Report Number`, `Date Reported`,
`Date of Occurrence`, `Time of Occurrence`,
`Date Case Closed`, `Case Closed`))
# Convert Crime Domain to binary (0 and 1)
crime_data_model$`Crime Domain` <- ifelse(crime_data_model$`Crime Domain` == "Violent Crime", 1, 0)
# Convert character columns to factors
crime_data_model$City <- as.factor(crime_data_model$City)
crime_data_model$`Crime Description` <- as.factor(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.factor(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.factor(crime_data_model$`Weapon Used`)
# Convert factors to numeric (preserving levels)
crime_data_model$City <- as.numeric(crime_data_model$City)
crime_data_model$`Crime Description` <- as.numeric(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.numeric(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.numeric(crime_data_model$`Weapon Used`)
crime_data_model$`Police Deployed` <- as.numeric(crime_data_model$`Police Deployed`)
# Data Splitting (reproducible)
set.seed(123)
train_index <- sample(1:nrow(crime_data_model), 0.8 * nrow(crime_data_model))
train_data <- crime_data_model[train_index, ]
test_data <- crime_data_model[-train_index, ]
# Prepare Data for randomForest
train_data$`Crime Domain` <- as.factor(train_data$`Crime Domain`)
test_data$`Crime Domain` <- as.factor(test_data$`Crime Domain`)
# Train randomForest Model
rf_model <- randomForest(`Crime Domain` ~ ., data = train_data, ntree = 500)
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
View(train_data)
View(train_data)
View(crime_data_model)
View(crime_data_model)
# Load necessary libraries
library(readr)  # For reading CSV files
# Load the data set
crime_data <- read_csv("crime_dataset_india.csv")
# View the first few rows to check if it's loaded correctly
head(crime_data)
colSums(is.na(crime_data))  # Shows count of missing values per column
# Keep a copy of the original dataset for visualization later
crime_data_original <- crime_data
# Drop unnecessary columns for classification
crime_data_model <- subset(crime_data, select = -c(`Report Number`, `Date Reported`,
`Date of Occurrence`, `Time of Occurrence`,
`Date Case Closed`, `Case Closed`))
str(crime_data_model)  # Show the structure of the dataset
crime_data_model$`Crime Domain` <- ifelse(crime_data_model$`Crime Domain` == "Violent Crime", 1, 0)
crime_data_model$`City` <- as.factor(crime_data_model$`City`)
crime_data_model$`Crime Description` <- as.factor(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.factor(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.factor(crime_data_model$`Weapon Used`)
crime_data_model$`City` <- as.numeric(crime_data_model$`City`)
crime_data_model$`Crime Description` <- as.numeric(crime_data_model$`Crime Description`)
crime_data_model$`Victim Gender` <- as.numeric(crime_data_model$`Victim Gender`)
crime_data_model$`Weapon Used` <- as.numeric(crime_data_model$`Weapon Used`)
#installing packages for data splitting training and testing
install.packages("caTools")
# loading the library
library(caTools)
set.seed(123)  # Ensures reproducibility
# Get total row count
total_rows <- nrow(crime_data_model)
# Create a shuffled sequence of row indices
shuffled_indices <- sample(total_rows)
# Define split point (80% training, 20% testing)
split_point <- round(0.8 * total_rows)
# Assign indices for training and testing sets
train_indices <- shuffled_indices[1:split_point]
test_indices <- shuffled_indices[(split_point + 1):total_rows]
# Create datasets using indices (no overlap possible)
train_data <- crime_data_model[train_indices, , drop = FALSE]
test_data <- crime_data_model[test_indices, , drop = FALSE]
# Verify no overlap
overlap <- intersect(train_indices, test_indices)
if (length(overlap) == 0) {
print("✅ No overlapping rows found. Data split is correct!")
} else {
print(paste("❌ Overlap detected! Number of overlapping rows:", length(overlap)))
}
# training xgboost model
install.packages("xgboost")
library(xgboost)
# Convert Data to Matrix
train_matrix <- as.matrix(subset(train_data, select = -`Crime Domain`))
test_matrix <- as.matrix(subset(test_data, select = -`Crime Domain`))
# Define Target Variable (Labels)
train_labels <- train_data$`Crime Domain`
test_labels <- test_data$`Crime Domain`
# Convert training and testing data to DMatrix
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)  # For evaluation
params <- list(
objective = "binary:logistic",
eval_metric = "error",
max_depth = 6,
min_child_weight = 1,
subsample = 0.8,
colsample_bytree = 0.8,
eta = 0.01,
lambda = 0.5,
alpha = 0.1
)
xgb_model <- xgb.train(
params = params,
data = dtrain,
nrounds = 300,
early_stopping_rounds = 20,
watchlist = list(train = dtrain, test = dtest)
)
# Generate predictions
predictions <- predict(xgb_model, test_matrix)
# Convert probabilities to class labels (0 or 1)
predicted_classes <- ifelse(predictions > 0.5, 1, 0)
# Calculate accuracy
accuracy <- sum(predicted_classes == test_labels) / length(test_labels)
# Print accuracy
print(paste("Model Accuracy:", round(accuracy * 100, 2), "%"))
# =========================================================
library(xgboost)
# Make sure 'Police.Deployed' column is numeric
train_data$`Police Deployed` <- as.numeric(train_data$`Police Deployed`)
# Ensure the new input tuple matches the preprocessed format
# Replace values below with your actual input values
new_tuple <- data.frame(
City = as.numeric(factor("Delhi", levels = levels(as.factor(train_data$City)))),
`Crime Code` = 197, # Numeric value (e.g., Crime Code for ASSAULT)
`Crime Description` = as.numeric(factor("ASSAULT", levels = levels(as.factor(train_data$`Crime Description`)))),
`Victim Age` = 61, # Numeric value for victim's age
`Victim Gender` = as.numeric(factor("F", levels = levels(as.factor(train_data$`Victim Gender`)))),
`Weapon Used` = as.numeric(factor("KNIFE", levels = levels(as.factor(train_data$`Weapon Used`)))),
`Police Deployed` = 10 # Numeric value representing the number of police deployed
)
# Ensure column names match exactly with training data feature names
colnames(new_tuple) <- colnames(train_matrix)
# Convert the new tuple to matrix format (required by xgboost)
new_tuple_matrix <- as.matrix(new_tuple)
# Predict using the trained XGBoost model
new_prediction <- predict(xgb_model, new_tuple_matrix)
# Convert probability to class label (0 for nonviolent, 1 for violent)
predicted_class <- ifelse(new_prediction > 0.5, "Violent Crime", "Nonviolent Crime")
# Output the result
print(paste("Predicted Crime Domain:", predicted_class))
print(new_prediction)
install.packages("xgboost")
hist(predictions, breaks = 30, col = "blue", main = "Distribution of Predictions",
xlab = "Predicted Probability", ylab = "Frequency", border = "white")
new_tuple <- data.frame(
City = as.numeric(factor("Delhi", levels = levels(as.factor(train_data$City)))),
`Crime Code` = 197, # Numeric value (e.g., Crime Code for ASSAULT)
`Crime Description` = as.numeric(factor("ASSAULT", levels = levels(as.factor(train_data$`Crime Description`)))),
`Victim Age` = 61, # Numeric value for victim's age
`Victim Gender` = as.numeric(factor("F", levels = levels(as.factor(train_data$`Victim Gender`)))),
`Weapon Used` = as.numeric(factor("KNIFE", levels = levels(as.factor(train_data$`Weapon Used`)))),
`Police Deployed` = 40 # Numeric value representing the number of police deployed
)
# Ensure column names match exactly with training data feature names
colnames(new_tuple) <- colnames(train_matrix)
# Convert the new tuple to matrix format (required by xgboost)
new_tuple_matrix <- as.matrix(new_tuple)
# Predict using the trained XGBoost model
new_prediction <- predict(xgb_model, new_tuple_matrix)
# Convert probability to class label (0 for nonviolent, 1 for violent)
predicted_class <- ifelse(new_prediction > 0.5, "Violent Crime", "Nonviolent Crime")
# Output the result
print(paste("Predicted Crime Domain:", predicted_class))
print(new_prediction)
hist(predictions, breaks = 30, col = "blue", main = "Distribution of Predictions",
xlab = "Predicted Probability", ylab = "Frequency", border = "white")
new_tuple <- data.frame(
City = as.numeric(factor("Delhi", levels = levels(as.factor(train_data$City)))),
`Crime Code` = 197, # Numeric value (e.g., Crime Code for ASSAULT)
`Crime Description` = as.numeric(factor("IDENTITY THEFT", levels = levels(as.factor(train_data$`Crime Description`)))),
`Victim Age` = 61, # Numeric value for victim's age
`Victim Gender` = as.numeric(factor("F", levels = levels(as.factor(train_data$`Victim Gender`)))),
`Weapon Used` = as.numeric(factor("KNIFE", levels = levels(as.factor(train_data$`Weapon Used`)))),
`Police Deployed` = 40 # Numeric value representing the number of police deployed
)
# Ensure column names match exactly with training data feature names
colnames(new_tuple) <- colnames(train_matrix)
# Convert the new tuple to matrix format (required by xgboost)
new_tuple_matrix <- as.matrix(new_tuple)
# Predict using the trained XGBoost model
new_prediction <- predict(xgb_model, new_tuple_matrix)
# Convert probability to class label (0 for nonviolent, 1 for violent)
predicted_class <- ifelse(new_prediction > 0.5, "Violent Crime", "Nonviolent Crime")
# Output the result
print(paste("Predicted Crime Domain:", predicted_class))
print(new_prediction)
hist(predictions, breaks = 30, col = "blue", main = "Distribution of Predictions",
xlab = "Predicted Probability", ylab = "Frequency", border = "white")
new_tuple <- data.frame(
City = as.numeric(factor("Delhi", levels = levels(as.factor(train_data$City)))),
`Crime Code` = 197, # Numeric value (e.g., Crime Code for ASSAULT)
`Crime Description` = as.numeric(factor("BURGLARY", levels = levels(as.factor(train_data$`Crime Description`)))),
`Victim Age` = 61, # Numeric value for victim's age
`Victim Gender` = as.numeric(factor("F", levels = levels(as.factor(train_data$`Victim Gender`)))),
`Weapon Used` = as.numeric(factor("KNIFE", levels = levels(as.factor(train_data$`Weapon Used`)))),
`Police Deployed` = 40 # Numeric value representing the number of police deployed
)
# Ensure column names match exactly with training data feature names
colnames(new_tuple) <- colnames(train_matrix)
# Convert the new tuple to matrix format (required by xgboost)
new_tuple_matrix <- as.matrix(new_tuple)
# Predict using the trained XGBoost model
new_prediction <- predict(xgb_model, new_tuple_matrix)
# Convert probability to class label (0 for nonviolent, 1 for violent)
predicted_class <- ifelse(new_prediction > 0.5, "Violent Crime", "Nonviolent Crime")
# Output the result
print(paste("Predicted Crime Domain:", predicted_class))
print(new_prediction)
hist(predictions, breaks = 30, col = "blue", main = "Distribution of Predictions",
xlab = "Predicted Probability", ylab = "Frequency", border = "white")
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
runApp('XG-OG-CODE-WITH-SHINY.R')
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
# SHINY APP
ui <- fluidPage(
theme = shinytheme("cosmo"),
titlePanel("Ten Year Coronary Artery Disease Classification"),
tabsetPanel(
tabPanel("Prediction",
sidebarLayout(
sidebarPanel(
numericInput("male", "Gender (1 = Male, 0 = Female)", 1, min = 0, max = 1),
numericInput("age", "Age", 52, min = 20, max = 100),
numericInput("education", "Education Level (1-4)", 4, min = 1, max = 4),
numericInput("currentSmoker", "Smoker (1 = Yes, 0 = No)", 1, min = 0, max = 1),
numericInput("cigsPerDay", "Cigarettes per Day", 30, min = 0, max = 50),
numericInput("BPMeds", "Blood Pressure Meds (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("prevalentStroke", "History of Stroke (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("prevalentHyp", "Hypertension (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("diabetes", "Diabetes (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("totChol", "Total Cholesterol", 346, min = 100, max = 600),
numericInput("sysBP", "Systolic Blood Pressure", 133, min = 80, max = 200),
numericInput("diaBP", "Diastolic Blood Pressure", 96, min = 50, max = 150),
numericInput("BMI", "Body Mass Index (BMI)", 25.95, min = 10, max = 50),
numericInput("heartRate", "Heart Rate (bpm)", 65, min = 40, max = 150),
numericInput("glucose", "Blood Glucose Level", 126, min = 50, max = 300),
actionButton("predict", "Predict")
),
mainPanel(
h3("Predicted Risk:"),
verbatimTextOutput("prediction"),
h3("Factors Affecting Your Risk:"),
plotOutput("risk_factors_plot"),
h3("Recommended Remedies:"),
verbatimTextOutput("remedies")
)
)
)
)
)
# Load Dataset
baseBRF <- read.csv("dataset-framingham-heart-study.csv")
# Load Dataset
baseBRF <- read.csv("dataset-framingham-heart-study.csv")
library(shiny)
library(xgboost)
library(caret)
library(pROC)
library(ggplot2)
library(shinythemes)
# Load Dataset
baseBRF <- read.csv("dataset-framingham-heart-study.csv")
baseBRF <- na.omit(baseBRF)
baseBRF$TenYearCHD <- as.factor(baseBRF$TenYearCHD)
# Data Splitting
set.seed(12345)
index <- createDataPartition(baseBRF$TenYearCHD, p=0.7, list=FALSE)
data.train <- baseBRF[index, ]
data.test  <- baseBRF[-index, ]
# Convert Target Variable to Numeric for XGBoost
train_labels <- as.numeric(data.train$TenYearCHD) - 1
test_labels  <- as.numeric(data.test$TenYearCHD) - 1
# Remove Target Variable from Features
train_matrix <- as.matrix(data.train[, -which(names(data.train) == "TenYearCHD")])
test_matrix  <- as.matrix(data.test[, -which(names(data.test) == "TenYearCHD")])
# Convert to XGBoost DMatrix Format
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest  <- xgb.DMatrix(data = test_matrix, label = test_labels)
# Define Parameters for XGBoost
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = 6,
eta = 0.01,
nrounds = 100,
min_child_weight = 3
)
# Train XGBoost Model
xgb_model <- xgb.train(params, dtrain, nrounds = params$nrounds,
watchlist = list(train = dtrain, test = dtest),
verbose = 0)
# SHINY APP
ui <- fluidPage(
theme = shinytheme("cosmo"),
titlePanel("Ten Year Coronary Artery Disease Classification"),
tabsetPanel(
tabPanel("Prediction",
sidebarLayout(
sidebarPanel(
numericInput("male", "Gender (1 = Male, 0 = Female)", 1, min = 0, max = 1),
numericInput("age", "Age", 52, min = 20, max = 100),
numericInput("education", "Education Level (1-4)", 4, min = 1, max = 4),
numericInput("currentSmoker", "Smoker (1 = Yes, 0 = No)", 1, min = 0, max = 1),
numericInput("cigsPerDay", "Cigarettes per Day", 30, min = 0, max = 50),
numericInput("BPMeds", "Blood Pressure Meds (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("prevalentStroke", "History of Stroke (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("prevalentHyp", "Hypertension (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("diabetes", "Diabetes (1 = Yes, 0 = No)", 0, min = 0, max = 1),
numericInput("totChol", "Total Cholesterol", 346, min = 100, max = 600),
numericInput("sysBP", "Systolic Blood Pressure", 133, min = 80, max = 200),
numericInput("diaBP", "Diastolic Blood Pressure", 96, min = 50, max = 150),
numericInput("BMI", "Body Mass Index (BMI)", 25.95, min = 10, max = 50),
numericInput("heartRate", "Heart Rate (bpm)", 65, min = 40, max = 150),
numericInput("glucose", "Blood Glucose Level", 126, min = 50, max = 300),
actionButton("predict", "Predict")
),
mainPanel(
h3("Predicted Risk:"),
verbatimTextOutput("prediction"),
h3("Factors Affecting Your Risk:"),
plotOutput("risk_factors_plot"),
h3("Recommended Remedies:"),
verbatimTextOutput("remedies")
)
)
)
)
)
server <- function(input, output) {
observeEvent(input$predict, {
new_input <- matrix(c(
input$male, input$age, input$education, input$currentSmoker, input$cigsPerDay,
input$BPMeds, input$prevalentStroke, input$prevalentHyp, input$diabetes,
input$totChol, input$sysBP, input$diaBP, input$BMI, input$heartRate, input$glucose
), nrow = 1)
dnew <- xgb.DMatrix(data = new_input)
new_pred_prob <- predict(xgb_model, newdata = dnew)
new_pred_label <- ifelse(new_pred_prob > 0.5, "High Risk", "Low Risk")
output$prediction <- renderText({
paste("Prediction:", new_pred_label, "| Probability:", round(new_pred_prob, 4))
})
healthy_values <- data.frame(
Factor = c("Cigarettes per Day", "Total Cholesterol", "Systolic BP", "Diastolic BP", "BMI", "Glucose"),
Patient_Value = c(input$cigsPerDay, input$totChol, input$sysBP, input$diaBP, input$BMI, input$glucose),
Healthy_Range = c(0, 200, 120, 80, 25, 100)
)
healthy_values$Difference <- healthy_values$Patient_Value - healthy_values$Healthy_Range
output$risk_factors_plot <- renderPlot({
ggplot(healthy_values, aes(x = reorder(Factor, Difference), y = Difference, fill = Difference)) +
geom_bar(stat = "identity", width = 0.6, show.legend = FALSE) +
scale_fill_gradient2(low = "green", mid = "yellow", high = "red", midpoint = 0) +
geom_text(aes(label = round(Difference, 1)), hjust = -0.2, size = 5) +
labs(title = "Factors Affecting CHD Risk", x = "Health Factor", y = "Difference from Healthy Value") +
theme_minimal() +
coord_flip()
})
remedies <- c()
if (input$cigsPerDay > 0) remedies <- c(remedies, "Reduce smoking or quit for better heart health.")
if (input$totChol > 200) remedies <- c(remedies, "Adopt a diet low in saturated fats and exercise more.")
if (input$sysBP > 120) remedies <- c(remedies, "Monitor your blood pressure and reduce salt intake.")
if (input$BMI > 25) remedies <- c(remedies, "Maintain a balanced diet and engage in regular exercise.")
if (input$glucose > 100) remedies <- c(remedies, "Control sugar intake and exercise to improve metabolism.")
output$remedies <- renderText({
if (length(remedies) == 0) {
"You are healthy! Keep up the good work!"
} else {
paste(remedies, collapse = "\n")
}
})
})
}
shinyApp(ui = ui, server = server)
runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
runApp('sarah-code.r')
runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
runApp('sarah-code.r')
runApp('sarah-code.r')
runApp('sarah-code.r')
runApp('sarah-code.r')
runApp('sarah-code.r')
runApp('sarah-code.r')
library(shiny); runApp('sarah-code.r')
library(ggplot2)
library(dplyr)
set.seed(123)
df <- data.frame(
x = 1:100,
y1 = cumsum(rnorm(100)),
y2 = cumsum(rnorm(100, mean = 0.5)),
y3 = cumsum(rnorm(100, mean = -0.3))
)
line_plot <- ggplot(df, aes(x = x, y = y1)) +
geom_line(color = "blue") +
labs(title = "Line Plot", x = "X Axis", y = "Y1 Value")
multi_line_plot <- ggplot(df) +
geom_line(aes(x = x, y = y1, color = "Y1")) +
geom_line(aes(x = x, y = y2, color = "Y2")) +
geom_line(aes(x = x, y = y3, color = "Y3")) +
labs(title = "Multi Line Plot", x = "X Axis", y = "Values", color = "Series")
df_long <- df %>%
select(x, y1, y2) %>%
pivot_longer(cols = c(y1, y2), names_to = "variable", values_to = "value")
library(ggplot2)
library(dplyr)
set.seed(123)
df <- data.frame(
x = 1:100,
y1 = cumsum(rnorm(100)),
y2 = cumsum(rnorm(100, mean = 0.5)),
y3 = cumsum(rnorm(100, mean = -0.3))
)
line_plot <- ggplot(df, aes(x = x, y = y1)) +
geom_line(color = "blue") +
labs(title = "Line Plot", x = "X Axis", y = "Y1 Value")
multi_line_plot <- ggplot(df) +
geom_line(aes(x = x, y = y1, color = "Y1")) +
geom_line(aes(x = x, y = y2, color = "Y2")) +
geom_line(aes(x = x, y = y3, color = "Y3")) +
labs(title = "Multi Line Plot", x = "X Axis", y = "Values", color = "Series")
df_long <- df %>%
select(x, y1, y2) %>%
pivot_longer(cols = c(y1, y2), names_to = "variable", values_to = "value")
library(ggplot2)
library(dplyr)
set.seed(123)
df <- data("USArrests")
line_plot <- ggplot(df, aes(x = x, y = y1)) +
geom_line(color = "blue") +
labs(title = "Line Plot", x = "X Axis", y = "Y1 Value")
library(shiny); runApp('XG-OG-CODE-WITH-SHINY.R')
install.packages("shinythemes")
